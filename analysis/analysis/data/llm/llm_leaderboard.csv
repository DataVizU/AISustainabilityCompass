Model,Average,ARC,HellaSwag,MMLU,TruthfulQA,Type,Precision,#Params (B)
Yi-34B,70.72,64.59,85.69,76.35,56.23,pretrained,torch.bfloat16,34.0
falcon-180B,68.74,69.8,88.95,70.54,45.67,pretrained,torch.bfloat16,179.52
falcon-180B,68.7,69.71,88.98,70.44,45.66,pretrained,torch.float16,179.52
falcon-180B,68.57,69.45,88.86,70.5,45.47,pretrained,8bit,179.52
falcon-180B,68.21,69.2,88.89,69.59,45.16,pretrained,4bit,179.52
Llama-2-70b-hf,67.35,67.32,87.33,69.83,44.92,pretrained,torch.float16,68.98
tigerbot-70b-base,66.08,62.46,83.61,65.49,52.76,pretrained,torch.float16,68.95
internlm-20b,64.27,60.49,82.13,61.85,52.61,pretrained,torch.float16,20.0
llama-65b,64.23,63.48,86.09,63.93,43.43,pretrained,torch.float16,65.29
llama-65b,64.23,63.48,86.09,63.93,43.43,pretrained,torch.float16,65.29
Mistral-7B-v0.1,62.4,59.98,83.31,64.16,42.15,pretrained,torch.float16,7.11
llama-30b,61.68,61.26,84.73,58.47,42.27,pretrained,torch.float16,32.53
falcon-40b,61.48,61.95,85.28,56.98,41.72,pretrained,torch.bfloat16,41.3
mpt-30b-chat,60.94,58.36,82.41,50.98,52.0,pretrained,torch.bfloat16,29.96
Yi-6B,59.42,55.55,76.42,63.85,41.86,pretrained,torch.bfloat16,6.0
Qwen-7B,59.37,51.37,78.47,59.84,47.79,pretrained,torch.bfloat16,7.72
tora-13b-v1.0,59.06,58.96,82.31,54.73,40.25,pretrained,torch.float16,12.85
Llama-2-13b-hf,58.66,59.39,82.13,55.77,37.38,pretrained,torch.float16,13.02
Llama-2-13B-fp16,58.63,59.3,82.15,55.67,37.39,pretrained,torch.float16,12.85
openbuddy-llama2-13b-v11.1-bf16,58.5,51.62,76.23,56.45,49.7,pretrained,torch.float16,12.88
leo-hessianai-13b,57.72,57.25,81.94,53.65,38.03,pretrained,torch.float16,12.85
llama-2-26b-trenchcoat-stack,57.29,55.03,79.9,53.73,40.48,pretrained,torch.float16,25.7
tigerbot-13b-base,57.13,53.84,77.05,53.57,44.06,pretrained,torch.bfloat16,13.0
Llama-2-13b-hf,56.9,58.11,80.97,54.34,34.17,pretrained,4bit,13.02
mpt-30b,56.15,55.89,82.41,47.93,38.38,pretrained,torch.float16,29.96
llama-13b,56.08,56.23,80.93,47.67,39.48,pretrained,torch.float16,13.02
llama-13b,56.04,56.14,80.92,47.61,39.48,pretrained,torch.float16,13.02
firefly-llama2-13b-pretrain,55.13,53.92,79.1,51.25,36.24,pretrained,torch.float16,12.97
Llama-2-7b-hf,54.32,53.07,78.59,46.87,38.76,pretrained,torch.float16,6.74
test_llama2_7b,54.31,53.07,78.57,46.86,38.75,pretrained,torch.float16,6.61
test-llama-2-7b,54.31,53.07,78.57,46.86,38.75,pretrained,torch.float16,7.0
araproje-llama2-7b-hf,54.3,53.07,78.57,46.8,38.75,pretrained,torch.float16,6.61
Flash-Llama-7B,54.3,53.07,78.57,46.8,38.75,pretrained,torch.float16,6.61
tora-7b-v1.0,53.74,52.47,78.68,45.9,37.9,pretrained,torch.float16,6.61
Llama-2-7b-hf,53.4,53.07,77.74,43.8,38.98,pretrained,4bit,6.74
Llama-2-7B-GPTQ,53.24,52.05,77.59,43.99,39.32,pretrained,torch.float16,9.05
Llama-2-7B-GPTQ,53.24,52.05,77.59,43.99,39.32,pretrained,GPTQ,9.05
tora-code-34b-v1.0,53.1,50.43,75.54,46.78,39.66,pretrained,torch.float16,33.48
gowizardlm,53.06,49.74,71.9,42.96,47.66,pretrained,torch.float16,6.76
mpt-7b-8k-chat,52.58,47.7,77.48,41.47,43.65,pretrained,torch.bfloat16,6.65
leo-hessianai-7b,52.15,51.96,75.84,42.85,37.94,pretrained,torch.float16,6.61
open_llama_13b,52.06,51.19,75.23,43.75,38.08,pretrained,torch.float16,12.85
stablelm-base-alpha-7b-v2,51.5,47.35,77.08,45.1,36.46,pretrained,torch.float16,6.89
stablelm-3b-4e1t,51.24,46.59,75.94,45.23,37.2,pretrained,torch.float16,2.8
firefly-llama2-7b-pretrain,50.89,48.63,74.83,41.04,39.08,pretrained,torch.float16,6.7
persimmon-8b-chat,49.79,44.97,73.3,44.98,35.93,pretrained,torch.bfloat16,8.32
llama-7b,49.72,51.02,77.82,35.71,34.33,pretrained,torch.float16,6.74
llama-base-7b,49.69,50.94,77.8,35.67,34.34,pretrained,torch.float16,6.61
persimmon-8b-base,48.84,42.75,71.14,43.63,37.85,pretrained,torch.bfloat16,8.32
galactica-30b,48.53,47.35,61.21,47.56,38.01,pretrained,torch.float16,29.97
open_llama_7b_v2,48.18,43.69,72.2,41.29,35.54,pretrained,torch.float16,6.61
Baichuan-7B,47.38,40.7,69.02,43.59,36.23,pretrained,torch.float32,7.0
mpt-7b,47.38,47.7,77.57,30.8,33.44,pretrained,torch.float16,6.65
falcon-7b,47.01,47.87,78.13,27.79,34.26,pretrained,torch.float16,6.92
mpt-7b,46.71,47.7,77.53,28.07,33.55,pretrained,torch.bfloat16,6.65
tora-code-13b-v1.0,46.35,44.45,69.29,36.67,34.98,pretrained,torch.float16,12.85
opt-66b,46.25,46.33,76.25,26.99,35.43,pretrained,torch.float16,65.72
codegen-16B-nl,46.23,46.76,71.87,32.35,33.95,pretrained,torch.float16,15.72
open_llama_7b,46.08,47.01,71.98,30.49,34.85,pretrained,torch.float16,6.61
rwkv-raven-14b,45.93,44.62,71.25,25.92,41.93,pretrained,torch.float16,13.89
open_llama_13b_600bt_preview,45.71,44.28,72.43,31.47,34.66,pretrained,torch.float16,12.85
palmyra-large,45.32,44.97,71.85,28.54,35.93,pretrained,torch.float16,20.26
CodeLlama-13b-hf,45.21,40.87,63.35,32.81,43.79,pretrained,torch.float16,12.85
CodeLlama-13b-hf,45.21,40.87,63.35,32.81,43.79,pretrained,torch.float16,13.02
opt-30b,44.79,43.26,74.07,26.66,35.16,pretrained,torch.float16,29.98
RedPajama-INCITE-7B-Base,44.65,46.25,71.63,27.68,33.03,pretrained,torch.float16,6.65
RedPajama-INCITE-Base-7B-v0.1,44.65,46.25,71.63,27.68,33.03,pretrained,torch.float16,6.65
Sheared-LLaMA-2.7B,44.24,41.72,71.01,26.92,37.32,pretrained,torch.float16,2.62
gpt-neox-20b,43.95,45.73,73.45,25.0,31.61,pretrained,torch.float16,20.74
7B-redpajama-conditional-alpha,43.86,42.58,69.91,26.53,36.42,pretrained,torch.float16,6.65
tora-code-7b-v1.0,43.68,40.7,65.86,33.34,34.84,pretrained,torch.float16,6.61
open_llama_3b_v2,43.44,40.27,71.6,27.12,34.78,pretrained,torch.float16,3.32
rwkv-4-14b-pile,43.42,44.45,71.07,26.12,32.04,pretrained,torch.float16,13.89
Flash-Llama-3B,43.32,40.1,71.56,26.88,34.74,pretrained,torch.float16,3.32
gpt-j-6b,42.92,41.38,67.54,26.78,35.96,pretrained,torch.float16,5.84
codegen-6B-nl,42.83,42.32,68.59,25.93,34.47,pretrained,torch.float16,6.85
fairseq-dense-6.7B,42.58,39.42,71.26,26.91,32.73,pretrained,torch.float16,6.65
pythia-12b-deduped,42.57,41.38,70.26,25.63,33.0,pretrained,torch.float16,11.59
opt-13b,42.53,39.93,71.2,24.9,34.1,pretrained,torch.float16,12.85
pythia-6.9b-deduped,42.51,41.3,67.05,26.48,35.19,pretrained,torch.float16,6.65
CodeLlama-7b-hf,42.42,39.93,60.8,31.12,37.82,pretrained,4bit,6.74
open_llama_7b_400bt_preview,42.27,39.51,65.88,27.64,36.04,pretrained,torch.float16,6.61
CodeLlama-7b-hf,42.13,39.85,59.58,30.47,38.62,pretrained,torch.float16,6.61
bloom-7b1,42.07,41.13,62.0,26.25,38.9,pretrained,torch.float16,7.07
test-22B,42.05,39.42,64.51,27.13,37.13,pretrained,torch.bfloat16,21.83
weblab-10b,41.9,39.51,65.76,26.29,36.02,pretrained,torch.float16,10.47
opt-6.7b,41.88,39.16,68.66,24.57,35.12,pretrained,torch.float16,6.66
pythia-12b,41.76,39.59,68.82,26.76,31.85,pretrained,torch.float16,11.59
RedPajama-INCITE-Base-3B-v1,41.3,40.19,64.77,27.03,33.23,pretrained,torch.float16,2.65
Open-LLongMA-3b,41.17,39.76,65.46,24.95,34.51,pretrained,torch.float16,3.0
rwkv-4-7b-pile,41.15,39.68,66.31,24.96,33.65,pretrained,torch.float16,7.19
open_llama_3b,41.1,39.85,62.65,26.94,34.97,pretrained,torch.float16,3.32
Cerebras-GPT-13B,40.81,38.14,60.01,25.92,39.19,pretrained,torch.float16,12.85
pythia-6.7b,40.65,40.1,65.0,24.64,32.85,pretrained,torch.float16,6.65
fairseq-dense-2.7B,40.13,33.79,65.74,26.44,34.57,pretrained,torch.float16,2.78
open_llama_7b_700bt_preview,40.02,35.07,61.79,25.45,37.77,pretrained,torch.float16,7.0
StellarX-4B-V0,40.0,36.95,61.9,26.85,34.3,pretrained,torch.float16,3.83
3B-redpajama-conditional-alpha,39.97,36.26,61.9,25.42,36.31,pretrained,torch.float16,2.65
pythia-2.7b,39.84,37.37,60.74,25.86,35.4,pretrained,torch.float16,2.91
xglm-7.5B,39.84,34.13,60.77,27.79,36.66,pretrained,torch.float16,7.49
pythia-2.8b-deduped,39.82,36.26,60.66,26.78,35.56,pretrained,torch.float16,2.91
openllama-3b-350bt,39.8,36.52,60.86,26.78,35.03,pretrained,torch.float16,3.32
open_llama_3b_350bt_preview,39.8,36.52,60.86,26.78,35.03,pretrained,torch.float16,3.32
Cerebras-GPT-6.7B,39.6,35.07,59.36,25.93,38.02,pretrained,torch.float16,6.66
opt-2.7b,39.56,33.96,61.43,25.43,37.43,pretrained,torch.float16,2.65
bloom-3b,39.32,35.75,54.37,26.59,40.57,pretrained,torch.float16,3.0
gpt-neo-2.7B,38.96,33.36,56.24,26.45,39.78,pretrained,torch.float16,2.72
StellarX-4B-V0.2,38.87,34.64,56.74,25.55,38.55,pretrained,torch.float16,2.65
rwkv-4-3b-pile,38.12,36.01,59.66,24.67,32.14,pretrained,torch.float16,2.86
palmyra-base,38.01,31.91,55.39,27.15,37.57,pretrained,torch.float16,5.05
xglm-4.5B,37.68,31.48,57.95,25.43,35.84,pretrained,torch.float16,5.08
stablelm-base-alpha-7b,37.54,32.0,51.78,26.21,40.19,pretrained,torch.float16,7.56
starcoder,37.38,30.29,47.97,30.0,41.28,pretrained,torch.float16,15.52
PULI-GPTrio,36.99,30.72,53.49,24.73,39.03,pretrained,torch.float16,7.06
CodeLlama-34b-hf,36.37,37.54,31.84,37.2,38.89,pretrained,torch.float16,33.74
CodeLlama-34b-hf,36.37,37.54,31.84,37.2,38.89,pretrained,torch.float16,33.48
bilingual-gpt-neox-4b-8k,36.34,28.58,43.94,25.38,47.48,pretrained,torch.float16,3.95
Cerebras-GPT-2.7B,36.23,29.1,49.29,25.17,41.37,pretrained,torch.float16,2.65
pile-7b-250b-tokens,35.32,29.27,46.29,25.25,40.49,pretrained,torch.bfloat16,5.87
bilingual-gpt-neox-4b,35.25,29.18,43.73,23.1,45.0,pretrained,torch.float16,3.95
polyglot-ko-12.8b,35.01,27.05,51.68,26.64,34.69,pretrained,torch.float16,13.06
codegen-6B-multi,34.92,27.22,41.11,25.71,45.65,pretrained,torch.float16,6.85
gpt3-finnish-13B,34.84,24.66,46.76,23.49,44.47,pretrained,torch.float16,13.26
stablelm-base-alpha-3b,33.66,26.45,42.24,25.43,40.5,pretrained,torch.float16,3.43
pile-7b,33.63,26.79,38.76,26.55,42.41,pretrained,torch.bfloat16,7.0
test_llama2_ko_7b,32.88,29.95,26.94,25.62,49.03,pretrained,torch.float16,6.67
Llama-2-13b-public,32.09,29.95,26.65,22.74,49.01,pretrained,torch.float16,12.85
Llama-2-3b-hf,31.88,26.96,26.52,23.33,50.71,pretrained,torch.bfloat16,3.37
proofGPT-v0.1-6.7B,31.8,23.29,28.45,24.57,50.87,pretrained,torch.float16,6.65
UltraLM-13b,31.79,29.44,25.99,23.12,48.61,pretrained,torch.float16,12.85
mpt-7b-storywriter,30.13,20.39,27.45,24.25,48.44,pretrained,torch.bfloat16,6.65
KoRWKV-6B,29.51,22.1,32.18,24.69,39.05,pretrained,torch.float16,6.53
