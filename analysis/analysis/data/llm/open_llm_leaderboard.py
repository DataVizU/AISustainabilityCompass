header = [
    "T",
    "Model",
    "Average ⬆️",
    "ARC",
    "HellaSwag",
    "MMLU",
    "TruthfulQA",
    "Type",
    "Precision",
    "#Params (B)",
    "model_name_for_query",
]


content = [
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/01-ai/Yi-34B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">01-ai/Yi-34B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_01-ai__Yi-34B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        70.72,
        64.59,
        85.69,
        76.35,
        56.23,
        "pretrained",
        "torch.bfloat16",
        34,
        "01-ai/Yi-34B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-180B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        68.74,
        69.8,
        88.95,
        70.54,
        45.67,
        "pretrained",
        "torch.bfloat16",
        179.52,
        "tiiuae/falcon-180B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-180B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        68.7,
        69.71,
        88.98,
        70.44,
        45.66,
        "pretrained",
        "torch.float16",
        179.52,
        "tiiuae/falcon-180B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-180B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        68.57,
        69.45,
        88.86,
        70.5,
        45.47,
        "pretrained",
        "8bit",
        179.52,
        "tiiuae/falcon-180B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-180B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-180B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        68.21,
        69.2,
        88.89,
        69.59,
        45.16,
        "pretrained",
        "4bit",
        179.52,
        "tiiuae/falcon-180B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-70b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">meta-llama/Llama-2-70b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_meta-llama__Llama-2-70b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        67.35,
        67.32,
        87.33,
        69.83,
        44.92,
        "pretrained",
        "torch.float16",
        68.98,
        "meta-llama/Llama-2-70b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TigerResearch/tigerbot-70b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TigerResearch/tigerbot-70b-base</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TigerResearch__tigerbot-70b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        66.08,
        62.46,
        83.61,
        65.49,
        52.76,
        "pretrained",
        "torch.float16",
        68.95,
        "TigerResearch/tigerbot-70b-base",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/internlm/internlm-20b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">internlm/internlm-20b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_internlm__internlm-20b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        64.27,
        60.49,
        82.13,
        61.85,
        52.61,
        "pretrained",
        "torch.float16",
        20,
        "internlm/internlm-20b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/huggyllama/llama-65b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">huggyllama/llama-65b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_huggyllama__llama-65b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        64.23,
        63.48,
        86.09,
        63.93,
        43.43,
        "pretrained",
        "torch.float16",
        65.29,
        "huggyllama/llama-65b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama-65b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llama-65b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        64.23,
        63.48,
        86.09,
        63.93,
        43.43,
        "pretrained",
        "torch.float16",
        65.29,
        "huggingface/llama-65b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mistralai/Mistral-7B-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mistralai/Mistral-7B-v0.1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mistralai__Mistral-7B-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        62.4,
        59.98,
        83.31,
        64.16,
        42.15,
        "pretrained",
        "torch.float16",
        7.11,
        "mistralai/Mistral-7B-v0.1",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama-30b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llama-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        61.68,
        61.26,
        84.73,
        58.47,
        42.27,
        "pretrained",
        "torch.float16",
        32.53,
        "huggingface/llama-30b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-40b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-40b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-40b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        61.48,
        61.95,
        85.28,
        56.98,
        41.72,
        "pretrained",
        "torch.bfloat16",
        41.3,
        "tiiuae/falcon-40b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-30b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-30b-chat</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-30b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        60.94,
        58.36,
        82.41,
        50.98,
        52,
        "pretrained",
        "torch.bfloat16",
        29.96,
        "mosaicml/mpt-30b-chat",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/01-ai/Yi-6B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">01-ai/Yi-6B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_01-ai__Yi-6B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        59.42,
        55.55,
        76.42,
        63.85,
        41.86,
        "pretrained",
        "torch.bfloat16",
        6,
        "01-ai/Yi-6B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Qwen/Qwen-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Qwen/Qwen-7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Qwen__Qwen-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        59.37,
        51.37,
        78.47,
        59.84,
        47.79,
        "pretrained",
        "torch.bfloat16",
        7.72,
        "Qwen/Qwen-7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/llm-agents/tora-13b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llm-agents/tora-13b-v1.0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llm-agents__tora-13b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        59.06,
        58.96,
        82.31,
        54.73,
        40.25,
        "pretrained",
        "torch.float16",
        12.85,
        "llm-agents/tora-13b-v1.0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">meta-llama/Llama-2-13b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_meta-llama__Llama-2-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        58.66,
        59.39,
        82.13,
        55.77,
        37.38,
        "pretrained",
        "torch.float16",
        13.02,
        "meta-llama/Llama-2-13b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TheBloke/Llama-2-13B-fp16" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TheBloke/Llama-2-13B-fp16</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TheBloke__Llama-2-13B-fp16" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        58.63,
        59.3,
        82.15,
        55.67,
        37.39,
        "pretrained",
        "torch.float16",
        12.85,
        "TheBloke/Llama-2-13B-fp16",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v11.1-bf16" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">OpenBuddy/openbuddy-llama2-13b-v11.1-bf16</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_OpenBuddy__openbuddy-llama2-13b-v11.1-bf16" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        58.5,
        51.62,
        76.23,
        56.45,
        49.7,
        "pretrained",
        "torch.float16",
        12.88,
        "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/LeoLM/leo-hessianai-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">LeoLM/leo-hessianai-13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_LeoLM__leo-hessianai-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        57.72,
        57.25,
        81.94,
        53.65,
        38.03,
        "pretrained",
        "torch.float16",
        12.85,
        "LeoLM/leo-hessianai-13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/chargoddard/llama-2-26b-trenchcoat-stack" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">chargoddard/llama-2-26b-trenchcoat-stack</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_chargoddard__llama-2-26b-trenchcoat-stack" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        57.29,
        55.03,
        79.9,
        53.73,
        40.48,
        "pretrained",
        "torch.float16",
        25.7,
        "chargoddard/llama-2-26b-trenchcoat-stack",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TigerResearch/tigerbot-13b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TigerResearch/tigerbot-13b-base</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TigerResearch__tigerbot-13b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        57.13,
        53.84,
        77.05,
        53.57,
        44.06,
        "pretrained",
        "torch.bfloat16",
        13,
        "TigerResearch/tigerbot-13b-base",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">meta-llama/Llama-2-13b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_meta-llama__Llama-2-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        56.9,
        58.11,
        80.97,
        54.34,
        34.17,
        "pretrained",
        "4bit",
        13.02,
        "meta-llama/Llama-2-13b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-30b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        56.15,
        55.89,
        82.41,
        47.93,
        38.38,
        "pretrained",
        "torch.float16",
        29.96,
        "mosaicml/mpt-30b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama-13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llama-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        56.08,
        56.23,
        80.93,
        47.67,
        39.48,
        "pretrained",
        "torch.float16",
        13.02,
        "huggingface/llama-13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/huggyllama/llama-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">huggyllama/llama-13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_huggyllama__llama-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        56.04,
        56.14,
        80.92,
        47.61,
        39.48,
        "pretrained",
        "torch.float16",
        13.02,
        "huggyllama/llama-13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/YeungNLP/firefly-llama2-13b-pretrain" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">YeungNLP/firefly-llama2-13b-pretrain</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_YeungNLP__firefly-llama2-13b-pretrain" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        55.13,
        53.92,
        79.1,
        51.25,
        36.24,
        "pretrained",
        "torch.float16",
        12.97,
        "YeungNLP/firefly-llama2-13b-pretrain",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">meta-llama/Llama-2-7b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_meta-llama__Llama-2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        54.32,
        53.07,
        78.59,
        46.87,
        38.76,
        "pretrained",
        "torch.float16",
        6.74,
        "meta-llama/Llama-2-7b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/yeen214/test_llama2_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">yeen214/test_llama2_7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_yeen214__test_llama2_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        54.31,
        53.07,
        78.57,
        46.86,
        38.75,
        "pretrained",
        "torch.float16",
        6.61,
        "yeen214/test_llama2_7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/bongchoi/test-llama-2-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">bongchoi/test-llama-2-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_bongchoi__test-llama-2-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        54.31,
        53.07,
        78.57,
        46.86,
        38.75,
        "pretrained",
        "torch.float16",
        7,
        "bongchoi/test-llama-2-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/ibranze/araproje-llama2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ibranze/araproje-llama2-7b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_ibranze__araproje-llama2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        54.3,
        53.07,
        78.57,
        46.8,
        38.75,
        "pretrained",
        "torch.float16",
        6.61,
        "ibranze/araproje-llama2-7b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TaylorAI/Flash-Llama-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TaylorAI/Flash-Llama-7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TaylorAI__Flash-Llama-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        54.3,
        53.07,
        78.57,
        46.8,
        38.75,
        "pretrained",
        "torch.float16",
        6.61,
        "TaylorAI/Flash-Llama-7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/llm-agents/tora-7b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llm-agents/tora-7b-v1.0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llm-agents__tora-7b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.74,
        52.47,
        78.68,
        45.9,
        37.9,
        "pretrained",
        "torch.float16",
        6.61,
        "llm-agents/tora-7b-v1.0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/meta-llama/Llama-2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">meta-llama/Llama-2-7b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_meta-llama__Llama-2-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.4,
        53.07,
        77.74,
        43.8,
        38.98,
        "pretrained",
        "4bit",
        6.74,
        "meta-llama/Llama-2-7b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TheBloke/Llama-2-7B-GPTQ" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TheBloke/Llama-2-7B-GPTQ</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TheBloke__Llama-2-7B-GPTQ" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.24,
        52.05,
        77.59,
        43.99,
        39.32,
        "pretrained",
        "torch.float16",
        9.05,
        "TheBloke/Llama-2-7B-GPTQ",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TheBloke/Llama-2-7B-GPTQ" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TheBloke/Llama-2-7B-GPTQ</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TheBloke__Llama-2-7B-GPTQ" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.24,
        52.05,
        77.59,
        43.99,
        39.32,
        "pretrained",
        "GPTQ",
        9.05,
        "TheBloke/Llama-2-7B-GPTQ",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/llm-agents/tora-code-34b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llm-agents/tora-code-34b-v1.0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llm-agents__tora-code-34b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.1,
        50.43,
        75.54,
        46.78,
        39.66,
        "pretrained",
        "torch.float16",
        33.48,
        "llm-agents/tora-code-34b-v1.0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/golaxy/gowizardlm" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">golaxy/gowizardlm</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_golaxy__gowizardlm" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        53.06,
        49.74,
        71.9,
        42.96,
        47.66,
        "pretrained",
        "torch.float16",
        6.76,
        "golaxy/gowizardlm",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-7b-8k-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-7b-8k-chat</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-7b-8k-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        52.58,
        47.7,
        77.48,
        41.47,
        43.65,
        "pretrained",
        "torch.bfloat16",
        6.65,
        "mosaicml/mpt-7b-8k-chat",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/LeoLM/leo-hessianai-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">LeoLM/leo-hessianai-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_LeoLM__leo-hessianai-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        52.15,
        51.96,
        75.84,
        42.85,
        37.94,
        "pretrained",
        "torch.float16",
        6.61,
        "LeoLM/leo-hessianai-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        52.06,
        51.19,
        75.23,
        43.75,
        38.08,
        "pretrained",
        "torch.float16",
        12.85,
        "openlm-research/open_llama_13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/stabilityai/stablelm-base-alpha-7b-v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai/stablelm-base-alpha-7b-v2</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_stabilityai__stablelm-base-alpha-7b-v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        51.5,
        47.35,
        77.08,
        45.1,
        36.46,
        "pretrained",
        "torch.float16",
        6.89,
        "stabilityai/stablelm-base-alpha-7b-v2",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/stabilityai/stablelm-3b-4e1t" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai/stablelm-3b-4e1t</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_stabilityai__stablelm-3b-4e1t" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        51.24,
        46.59,
        75.94,
        45.23,
        37.2,
        "pretrained",
        "torch.float16",
        2.8,
        "stabilityai/stablelm-3b-4e1t",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/YeungNLP/firefly-llama2-7b-pretrain" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">YeungNLP/firefly-llama2-7b-pretrain</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_YeungNLP__firefly-llama2-7b-pretrain" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        50.89,
        48.63,
        74.83,
        41.04,
        39.08,
        "pretrained",
        "torch.float16",
        6.7,
        "YeungNLP/firefly-llama2-7b-pretrain",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/adept/persimmon-8b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">adept/persimmon-8b-chat</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_adept__persimmon-8b-chat" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        49.79,
        44.97,
        73.3,
        44.98,
        35.93,
        "pretrained",
        "torch.bfloat16",
        8.32,
        "adept/persimmon-8b-chat",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llama-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llama-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        49.72,
        51.02,
        77.82,
        35.71,
        34.33,
        "pretrained",
        "torch.float16",
        6.74,
        "huggingface/llama-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/DevaMalla/llama-base-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">DevaMalla/llama-base-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_DevaMalla__llama-base-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        49.69,
        50.94,
        77.8,
        35.67,
        34.34,
        "pretrained",
        "torch.float16",
        6.61,
        "DevaMalla/llama-base-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/adept/persimmon-8b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">adept/persimmon-8b-base</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_adept__persimmon-8b-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        48.84,
        42.75,
        71.14,
        43.63,
        37.85,
        "pretrained",
        "torch.bfloat16",
        8.32,
        "adept/persimmon-8b-base",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/galactica-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/galactica-30b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__galactica-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        48.53,
        47.35,
        61.21,
        47.56,
        38.01,
        "pretrained",
        "torch.float16",
        29.97,
        "facebook/galactica-30b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_7b_v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_7b_v2</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_7b_v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        48.18,
        43.69,
        72.2,
        41.29,
        35.54,
        "pretrained",
        "torch.float16",
        6.61,
        "openlm-research/open_llama_7b_v2",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/baichuan-inc/Baichuan-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">baichuan-inc/Baichuan-7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_baichuan-inc__Baichuan-7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        47.38,
        40.7,
        69.02,
        43.59,
        36.23,
        "pretrained",
        "torch.float32",
        7,
        "baichuan-inc/Baichuan-7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        47.38,
        47.7,
        77.57,
        30.8,
        33.44,
        "pretrained",
        "torch.float16",
        6.65,
        "mosaicml/mpt-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/tiiuae/falcon-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">tiiuae/falcon-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_tiiuae__falcon-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        47.01,
        47.87,
        78.13,
        27.79,
        34.26,
        "pretrained",
        "torch.float16",
        6.92,
        "tiiuae/falcon-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        46.71,
        47.7,
        77.53,
        28.07,
        33.55,
        "pretrained",
        "torch.bfloat16",
        6.65,
        "mosaicml/mpt-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/llm-agents/tora-code-13b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llm-agents/tora-code-13b-v1.0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llm-agents__tora-code-13b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        46.35,
        44.45,
        69.29,
        36.67,
        34.98,
        "pretrained",
        "torch.float16",
        12.85,
        "llm-agents/tora-code-13b-v1.0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/opt-66b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/opt-66b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__opt-66b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        46.25,
        46.33,
        76.25,
        26.99,
        35.43,
        "pretrained",
        "torch.float16",
        65.72,
        "facebook/opt-66b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Salesforce/codegen-16B-nl" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Salesforce/codegen-16B-nl</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Salesforce__codegen-16B-nl" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        46.23,
        46.76,
        71.87,
        32.35,
        33.95,
        "pretrained",
        "torch.float16",
        15.72,
        "Salesforce/codegen-16B-nl",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        46.08,
        47.01,
        71.98,
        30.49,
        34.85,
        "pretrained",
        "torch.float16",
        6.61,
        "openlm-research/open_llama_7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/RWKV/rwkv-raven-14b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">RWKV/rwkv-raven-14b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_RWKV__rwkv-raven-14b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        45.93,
        44.62,
        71.25,
        25.92,
        41.93,
        "pretrained",
        "torch.float16",
        13.89,
        "RWKV/rwkv-raven-14b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/klosax/open_llama_13b_600bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">klosax/open_llama_13b_600bt_preview</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_klosax__open_llama_13b_600bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        45.71,
        44.28,
        72.43,
        31.47,
        34.66,
        "pretrained",
        "torch.float16",
        12.85,
        "klosax/open_llama_13b_600bt_preview",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Writer/palmyra-large" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Writer/palmyra-large</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Writer__palmyra-large" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        45.32,
        44.97,
        71.85,
        28.54,
        35.93,
        "pretrained",
        "torch.float16",
        20.26,
        "Writer/palmyra-large",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/NousResearch/CodeLlama-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">NousResearch/CodeLlama-13b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_NousResearch__CodeLlama-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        45.21,
        40.87,
        63.35,
        32.81,
        43.79,
        "pretrained",
        "torch.float16",
        12.85,
        "NousResearch/CodeLlama-13b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/codellama/CodeLlama-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">codellama/CodeLlama-13b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_codellama__CodeLlama-13b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        45.21,
        40.87,
        63.35,
        32.81,
        43.79,
        "pretrained",
        "torch.float16",
        13.02,
        "codellama/CodeLlama-13b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/opt-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/opt-30b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__opt-30b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        44.79,
        43.26,
        74.07,
        26.66,
        35.16,
        "pretrained",
        "torch.float16",
        29.98,
        "facebook/opt-30b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">togethercomputer/RedPajama-INCITE-7B-Base</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_togethercomputer__RedPajama-INCITE-7B-Base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        44.65,
        46.25,
        71.63,
        27.68,
        33.03,
        "pretrained",
        "torch.float16",
        6.65,
        "togethercomputer/RedPajama-INCITE-7B-Base",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">togethercomputer/RedPajama-INCITE-Base-7B-v0.1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_togethercomputer__RedPajama-INCITE-Base-7B-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        44.65,
        46.25,
        71.63,
        27.68,
        33.03,
        "pretrained",
        "torch.float16",
        6.65,
        "togethercomputer/RedPajama-INCITE-Base-7B-v0.1",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/princeton-nlp/Sheared-LLaMA-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">princeton-nlp/Sheared-LLaMA-2.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_princeton-nlp__Sheared-LLaMA-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        44.24,
        41.72,
        71.01,
        26.92,
        37.32,
        "pretrained",
        "torch.float16",
        2.62,
        "princeton-nlp/Sheared-LLaMA-2.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/gpt-neox-20b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/gpt-neox-20b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__gpt-neox-20b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.95,
        45.73,
        73.45,
        25,
        31.61,
        "pretrained",
        "torch.float16",
        20.74,
        "EleutherAI/gpt-neox-20b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Rallio67/7B-redpajama-conditional-alpha" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Rallio67/7B-redpajama-conditional-alpha</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Rallio67__7B-redpajama-conditional-alpha" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.86,
        42.58,
        69.91,
        26.53,
        36.42,
        "pretrained",
        "torch.float16",
        6.65,
        "Rallio67/7B-redpajama-conditional-alpha",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/llm-agents/tora-code-7b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">llm-agents/tora-code-7b-v1.0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_llm-agents__tora-code-7b-v1.0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.68,
        40.7,
        65.86,
        33.34,
        34.84,
        "pretrained",
        "torch.float16",
        6.61,
        "llm-agents/tora-code-7b-v1.0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_3b_v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_3b_v2</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_3b_v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.44,
        40.27,
        71.6,
        27.12,
        34.78,
        "pretrained",
        "torch.float16",
        3.32,
        "openlm-research/open_llama_3b_v2",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/RWKV/rwkv-4-14b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">RWKV/rwkv-4-14b-pile</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_RWKV__rwkv-4-14b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.42,
        44.45,
        71.07,
        26.12,
        32.04,
        "pretrained",
        "torch.float16",
        13.89,
        "RWKV/rwkv-4-14b-pile",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TaylorAI/Flash-Llama-3B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TaylorAI/Flash-Llama-3B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TaylorAI__Flash-Llama-3B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        43.32,
        40.1,
        71.56,
        26.88,
        34.74,
        "pretrained",
        "torch.float16",
        3.32,
        "TaylorAI/Flash-Llama-3B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/gpt-j-6b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/gpt-j-6b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__gpt-j-6b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.92,
        41.38,
        67.54,
        26.78,
        35.96,
        "pretrained",
        "torch.float16",
        5.84,
        "EleutherAI/gpt-j-6b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Salesforce/codegen-6B-nl" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Salesforce/codegen-6B-nl</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Salesforce__codegen-6B-nl" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.83,
        42.32,
        68.59,
        25.93,
        34.47,
        "pretrained",
        "torch.float16",
        6.85,
        "Salesforce/codegen-6B-nl",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/KoboldAI/fairseq-dense-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">KoboldAI/fairseq-dense-6.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_KoboldAI__fairseq-dense-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.58,
        39.42,
        71.26,
        26.91,
        32.73,
        "pretrained",
        "torch.float16",
        6.65,
        "KoboldAI/fairseq-dense-6.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-12b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-12b-deduped</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-12b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.57,
        41.38,
        70.26,
        25.63,
        33,
        "pretrained",
        "torch.float16",
        11.59,
        "EleutherAI/pythia-12b-deduped",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/opt-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/opt-13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__opt-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.53,
        39.93,
        71.2,
        24.9,
        34.1,
        "pretrained",
        "torch.float16",
        12.85,
        "facebook/opt-13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-6.9b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-6.9b-deduped</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-6.9b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.51,
        41.3,
        67.05,
        26.48,
        35.19,
        "pretrained",
        "torch.float16",
        6.65,
        "EleutherAI/pythia-6.9b-deduped",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/codellama/CodeLlama-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">codellama/CodeLlama-7b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_codellama__CodeLlama-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.42,
        39.93,
        60.8,
        31.12,
        37.82,
        "pretrained",
        "4bit",
        6.74,
        "codellama/CodeLlama-7b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/klosax/open_llama_7b_400bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">klosax/open_llama_7b_400bt_preview</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_klosax__open_llama_7b_400bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.27,
        39.51,
        65.88,
        27.64,
        36.04,
        "pretrained",
        "torch.float16",
        6.61,
        "klosax/open_llama_7b_400bt_preview",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/NousResearch/CodeLlama-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">NousResearch/CodeLlama-7b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_NousResearch__CodeLlama-7b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.13,
        39.85,
        59.58,
        30.47,
        38.62,
        "pretrained",
        "torch.float16",
        6.61,
        "NousResearch/CodeLlama-7b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/bigscience/bloom-7b1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">bigscience/bloom-7b1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_bigscience__bloom-7b1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.07,
        41.13,
        62,
        26.25,
        38.9,
        "pretrained",
        "torch.float16",
        7.07,
        "bigscience/bloom-7b1",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Devio/test-22B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Devio/test-22B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Devio__test-22B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        42.05,
        39.42,
        64.51,
        27.13,
        37.13,
        "pretrained",
        "torch.bfloat16",
        21.83,
        "Devio/test-22B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/matsuo-lab/weblab-10b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">matsuo-lab/weblab-10b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_matsuo-lab__weblab-10b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.9,
        39.51,
        65.76,
        26.29,
        36.02,
        "pretrained",
        "torch.float16",
        10.47,
        "matsuo-lab/weblab-10b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/opt-6.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/opt-6.7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__opt-6.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.88,
        39.16,
        68.66,
        24.57,
        35.12,
        "pretrained",
        "torch.float16",
        6.66,
        "facebook/opt-6.7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-12b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-12b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-12b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.76,
        39.59,
        68.82,
        26.76,
        31.85,
        "pretrained",
        "torch.float16",
        11.59,
        "EleutherAI/pythia-12b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">togethercomputer/RedPajama-INCITE-Base-3B-v1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_togethercomputer__RedPajama-INCITE-Base-3B-v1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.3,
        40.19,
        64.77,
        27.03,
        33.23,
        "pretrained",
        "torch.float16",
        2.65,
        "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/conceptofmind/Open-LLongMA-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">conceptofmind/Open-LLongMA-3b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_conceptofmind__Open-LLongMA-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.17,
        39.76,
        65.46,
        24.95,
        34.51,
        "pretrained",
        "torch.float16",
        3,
        "conceptofmind/Open-LLongMA-3b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/RWKV/rwkv-4-7b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">RWKV/rwkv-4-7b-pile</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_RWKV__rwkv-4-7b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.15,
        39.68,
        66.31,
        24.96,
        33.65,
        "pretrained",
        "torch.float16",
        7.19,
        "RWKV/rwkv-4-7b-pile",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_3b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        41.1,
        39.85,
        62.65,
        26.94,
        34.97,
        "pretrained",
        "torch.float16",
        3.32,
        "openlm-research/open_llama_3b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/cerebras/Cerebras-GPT-13B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">cerebras/Cerebras-GPT-13B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_cerebras__Cerebras-GPT-13B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        40.81,
        38.14,
        60.01,
        25.92,
        39.19,
        "pretrained",
        "torch.float16",
        12.85,
        "cerebras/Cerebras-GPT-13B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-6.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-6.7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-6.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        40.65,
        40.1,
        65,
        24.64,
        32.85,
        "pretrained",
        "torch.float16",
        6.65,
        "EleutherAI/pythia-6.7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/KoboldAI/fairseq-dense-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">KoboldAI/fairseq-dense-2.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_KoboldAI__fairseq-dense-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        40.13,
        33.79,
        65.74,
        26.44,
        34.57,
        "pretrained",
        "torch.float16",
        2.78,
        "KoboldAI/fairseq-dense-2.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openlm-research/open_llama_7b_700bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openlm-research/open_llama_7b_700bt_preview</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openlm-research__open_llama_7b_700bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        40.02,
        35.07,
        61.79,
        25.45,
        37.77,
        "pretrained",
        "torch.float16",
        7,
        "openlm-research/open_llama_7b_700bt_preview",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Dampish/StellarX-4B-V0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Dampish/StellarX-4B-V0</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Dampish__StellarX-4B-V0" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        40,
        36.95,
        61.9,
        26.85,
        34.3,
        "pretrained",
        "torch.float16",
        3.83,
        "Dampish/StellarX-4B-V0",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Rallio67/3B-redpajama-conditional-alpha" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Rallio67/3B-redpajama-conditional-alpha</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Rallio67__3B-redpajama-conditional-alpha" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.97,
        36.26,
        61.9,
        25.42,
        36.31,
        "pretrained",
        "torch.float16",
        2.65,
        "Rallio67/3B-redpajama-conditional-alpha",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-2.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-2.7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-2.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.84,
        37.37,
        60.74,
        25.86,
        35.4,
        "pretrained",
        "torch.float16",
        2.91,
        "EleutherAI/pythia-2.7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/xglm-7.5B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/xglm-7.5B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__xglm-7.5B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.84,
        34.13,
        60.77,
        27.79,
        36.66,
        "pretrained",
        "torch.float16",
        7.49,
        "facebook/xglm-7.5B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/pythia-2.8b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/pythia-2.8b-deduped</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__pythia-2.8b-deduped" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.82,
        36.26,
        60.66,
        26.78,
        35.56,
        "pretrained",
        "torch.float16",
        2.91,
        "EleutherAI/pythia-2.8b-deduped",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/klosax/openllama-3b-350bt" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">klosax/openllama-3b-350bt</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_klosax__openllama-3b-350bt" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.8,
        36.52,
        60.86,
        26.78,
        35.03,
        "pretrained",
        "torch.float16",
        3.32,
        "klosax/openllama-3b-350bt",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/klosax/open_llama_3b_350bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">klosax/open_llama_3b_350bt_preview</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_klosax__open_llama_3b_350bt_preview" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.8,
        36.52,
        60.86,
        26.78,
        35.03,
        "pretrained",
        "torch.float16",
        3.32,
        "klosax/open_llama_3b_350bt_preview",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/cerebras/Cerebras-GPT-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">cerebras/Cerebras-GPT-6.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_cerebras__Cerebras-GPT-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.6,
        35.07,
        59.36,
        25.93,
        38.02,
        "pretrained",
        "torch.float16",
        6.66,
        "cerebras/Cerebras-GPT-6.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/opt-2.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/opt-2.7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__opt-2.7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.56,
        33.96,
        61.43,
        25.43,
        37.43,
        "pretrained",
        "torch.float16",
        2.65,
        "facebook/opt-2.7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/bigscience/bloom-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">bigscience/bloom-3b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_bigscience__bloom-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        39.32,
        35.75,
        54.37,
        26.59,
        40.57,
        "pretrained",
        "torch.float16",
        3,
        "bigscience/bloom-3b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/gpt-neo-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/gpt-neo-2.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__gpt-neo-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        38.96,
        33.36,
        56.24,
        26.45,
        39.78,
        "pretrained",
        "torch.float16",
        2.72,
        "EleutherAI/gpt-neo-2.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Dampish/StellarX-4B-V0.2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Dampish/StellarX-4B-V0.2</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Dampish__StellarX-4B-V0.2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        38.87,
        34.64,
        56.74,
        25.55,
        38.55,
        "pretrained",
        "torch.float16",
        2.65,
        "Dampish/StellarX-4B-V0.2",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/RWKV/rwkv-4-3b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">RWKV/rwkv-4-3b-pile</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_RWKV__rwkv-4-3b-pile" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        38.12,
        36.01,
        59.66,
        24.67,
        32.14,
        "pretrained",
        "torch.float16",
        2.86,
        "RWKV/rwkv-4-3b-pile",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Writer/palmyra-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Writer/palmyra-base</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Writer__palmyra-base" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        38.01,
        31.91,
        55.39,
        27.15,
        37.57,
        "pretrained",
        "torch.float16",
        5.05,
        "Writer/palmyra-base",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/facebook/xglm-4.5B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">facebook/xglm-4.5B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_facebook__xglm-4.5B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        37.68,
        31.48,
        57.95,
        25.43,
        35.84,
        "pretrained",
        "torch.float16",
        5.08,
        "facebook/xglm-4.5B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/stabilityai/stablelm-base-alpha-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai/stablelm-base-alpha-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_stabilityai__stablelm-base-alpha-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        37.54,
        32,
        51.78,
        26.21,
        40.19,
        "pretrained",
        "torch.float16",
        7.56,
        "stabilityai/stablelm-base-alpha-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/bigcode/starcoder" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">bigcode/starcoder</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_bigcode__starcoder" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        37.38,
        30.29,
        47.97,
        30,
        41.28,
        "pretrained",
        "torch.float16",
        15.52,
        "bigcode/starcoder",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/NYTK/PULI-GPTrio" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">NYTK/PULI-GPTrio</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_NYTK__PULI-GPTrio" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        36.99,
        30.72,
        53.49,
        24.73,
        39.03,
        "pretrained",
        "torch.float16",
        7.06,
        "NYTK/PULI-GPTrio",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/codellama/CodeLlama-34b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">codellama/CodeLlama-34b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_codellama__CodeLlama-34b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        36.37,
        37.54,
        31.84,
        37.2,
        38.89,
        "pretrained",
        "torch.float16",
        33.74,
        "codellama/CodeLlama-34b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/NousResearch/CodeLlama-34b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">NousResearch/CodeLlama-34b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_NousResearch__CodeLlama-34b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        36.37,
        37.54,
        31.84,
        37.2,
        38.89,
        "pretrained",
        "torch.float16",
        33.48,
        "NousResearch/CodeLlama-34b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-8k" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna/bilingual-gpt-neox-4b-8k</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_rinna__bilingual-gpt-neox-4b-8k" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        36.34,
        28.58,
        43.94,
        25.38,
        47.48,
        "pretrained",
        "torch.float16",
        3.95,
        "rinna/bilingual-gpt-neox-4b-8k",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/cerebras/Cerebras-GPT-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">cerebras/Cerebras-GPT-2.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_cerebras__Cerebras-GPT-2.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        36.23,
        29.1,
        49.29,
        25.17,
        41.37,
        "pretrained",
        "torch.float16",
        2.65,
        "cerebras/Cerebras-GPT-2.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Kunhao/pile-7b-250b-tokens" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Kunhao/pile-7b-250b-tokens</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Kunhao__pile-7b-250b-tokens" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        35.32,
        29.27,
        46.29,
        25.25,
        40.49,
        "pretrained",
        "torch.bfloat16",
        5.87,
        "Kunhao/pile-7b-250b-tokens",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/rinna/bilingual-gpt-neox-4b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rinna/bilingual-gpt-neox-4b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_rinna__bilingual-gpt-neox-4b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        35.25,
        29.18,
        43.73,
        23.1,
        45,
        "pretrained",
        "torch.float16",
        3.95,
        "rinna/bilingual-gpt-neox-4b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/EleutherAI/polyglot-ko-12.8b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">EleutherAI/polyglot-ko-12.8b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_EleutherAI__polyglot-ko-12.8b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        35.01,
        27.05,
        51.68,
        26.64,
        34.69,
        "pretrained",
        "torch.float16",
        13.06,
        "EleutherAI/polyglot-ko-12.8b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Salesforce/codegen-6B-multi" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Salesforce/codegen-6B-multi</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Salesforce__codegen-6B-multi" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        34.92,
        27.22,
        41.11,
        25.71,
        45.65,
        "pretrained",
        "torch.float16",
        6.85,
        "Salesforce/codegen-6B-multi",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/TurkuNLP/gpt3-finnish-13B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">TurkuNLP/gpt3-finnish-13B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_TurkuNLP__gpt3-finnish-13B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        34.84,
        24.66,
        46.76,
        23.49,
        44.47,
        "pretrained",
        "torch.float16",
        13.26,
        "TurkuNLP/gpt3-finnish-13B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/stabilityai/stablelm-base-alpha-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">stabilityai/stablelm-base-alpha-3b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_stabilityai__stablelm-base-alpha-3b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        33.66,
        26.45,
        42.24,
        25.43,
        40.5,
        "pretrained",
        "torch.float16",
        3.43,
        "stabilityai/stablelm-base-alpha-3b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/Kunhao/pile-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Kunhao/pile-7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_Kunhao__pile-7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        33.63,
        26.79,
        38.76,
        26.55,
        42.41,
        "pretrained",
        "torch.bfloat16",
        7,
        "Kunhao/pile-7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/yeen214/test_llama2_ko_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">yeen214/test_llama2_ko_7b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_yeen214__test_llama2_ko_7b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        32.88,
        29.95,
        26.94,
        25.62,
        49.03,
        "pretrained",
        "torch.float16",
        6.67,
        "yeen214/test_llama2_ko_7b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/porkorbeef/Llama-2-13b-public" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">porkorbeef/Llama-2-13b-public</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_porkorbeef__Llama-2-13b-public" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        32.09,
        29.95,
        26.65,
        22.74,
        49.01,
        "pretrained",
        "torch.float16",
        12.85,
        "porkorbeef/Llama-2-13b-public",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/winglian/Llama-2-3b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">winglian/Llama-2-3b-hf</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_winglian__Llama-2-3b-hf" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        31.88,
        26.96,
        26.52,
        23.33,
        50.71,
        "pretrained",
        "torch.bfloat16",
        3.37,
        "winglian/Llama-2-3b-hf",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/hoskinson-center/proofGPT-v0.1-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">hoskinson-center/proofGPT-v0.1-6.7B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_hoskinson-center__proofGPT-v0.1-6.7B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        31.8,
        23.29,
        28.45,
        24.57,
        50.87,
        "pretrained",
        "torch.float16",
        6.65,
        "hoskinson-center/proofGPT-v0.1-6.7B",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/openbmb/UltraLM-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">openbmb/UltraLM-13b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_openbmb__UltraLM-13b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        31.79,
        29.44,
        25.99,
        23.12,
        48.61,
        "pretrained",
        "torch.float16",
        12.85,
        "openbmb/UltraLM-13b",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/mosaicml/mpt-7b-storywriter" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">mosaicml/mpt-7b-storywriter</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_mosaicml__mpt-7b-storywriter" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        30.13,
        20.39,
        27.45,
        24.25,
        48.44,
        "pretrained",
        "torch.bfloat16",
        6.65,
        "mosaicml/mpt-7b-storywriter",
    ],
    [
        "🟢",
        '<a target="_blank" href="https://huggingface.co/beomi/KoRWKV-6B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">beomi/KoRWKV-6B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/details_beomi__KoRWKV-6B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">📑</a>',
        29.51,
        22.1,
        32.18,
        24.69,
        39.05,
        "pretrained",
        "torch.float16",
        6.53,
        "beomi/KoRWKV-6B",
    ],
]
